{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "\n",
    "## Conrad Appel & Eric Hawkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as p\n",
    "from skimage.feature import match_template\n",
    "import _pickle as cPickle\n",
    "from skimage.feature import daisy\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from random import randint\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "numlabels = 10\n",
    "\n",
    "\n",
    "###\n",
    "# Download dataset from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "# save all files to ./lab3/imgs/\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dics = []\n",
    "for root, directory, files in os.walk('imgs'):\n",
    "    for f in files:\n",
    "        if 'data_batch' in f:\n",
    "            with open(root+'/'+f, 'rb') as fo:\n",
    "                dics.append(cPickle.load(fo, encoding='latin1'))\n",
    "                break\n",
    "total_imgs = []\n",
    "for dic in dics:\n",
    "    for i in range(len(dic['data'])):\n",
    "        curpic = []\n",
    "        curpic.append(dic['data'][i]) # 1D img (1024 R, 1024 G, 1024 B)\n",
    "        curpic.append(dic['labels'][i]) # int representing the label\n",
    "        total_imgs.append(curpic)\n",
    "        \n",
    "total_imgs = np.array(total_imgs)\n",
    "imgs_df = p.DataFrame(total_imgs)\n",
    "imgs_df.columns = ['oneDColor', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "with open('./imgs/batches.meta', 'rb') as fo:\n",
    "    labels_tmp = cPickle.load(fo, encoding='latin1')\n",
    "    for i in range(len(labels_tmp['label_names'])):\n",
    "        labels[i] = labels_tmp['label_names'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def toGrayscale(img):\n",
    "    r, g, b = img[:1024], img[1024:2048], img[2048:]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "imgs_df['oneDGray'] = imgs_df['oneDColor'].apply(toGrayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,10)\n",
    "for label in range(10):\n",
    "    axes[label].axis('off')\n",
    "    axes[label].imshow(imgs_df.loc[lambda df: df.label == label]['oneDGray'].sample(n=1).values[0].reshape((32,32)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Dimensionality Reduction via PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Principal Components Analysis\n",
    "pcas = []\n",
    "for label in range(numlabels):\n",
    "    x = imgs_df.loc[lambda df: df.label == label]\n",
    "    \n",
    "    pixels_are_cols = np.zeros(shape=(len(x), 1024))\n",
    "    for i in range(len(x)):\n",
    "        cur_pic = x['oneDGray'].values[i]\n",
    "        for j in range(1024):\n",
    "            pixels_are_cols[i][j] = cur_pic[j]\n",
    "    \n",
    "    x = pixels_are_cols\n",
    "    y = [True]*len(x)\n",
    "    n_comps = 175\n",
    "\n",
    "    pca = PCA(n_components=n_comps)\n",
    "    X_pca = pca.fit(x)\n",
    "    pcas.append((x, pca, X_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, numlabels)\n",
    "for label in range(numlabels):\n",
    "    axis = axes[label] if numlabels > 1 else axes\n",
    "    eigenpics = pcas[label][1].components_.reshape((n_comps, 32, 32))\n",
    "    np.random.shuffle(pcas[label][0])\n",
    "    recd = pca.inverse_transform(pca.transform(pcas[label][0][0].reshape(1, -1)))\n",
    "    axis.axis('off')\n",
    "    axis.imshow(recd.reshape((32,32)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Dimensionality Reduction via Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel Principal Component Analysis\n",
    "kpcas = []\n",
    "for label in range(numlabels):\n",
    "    x = imgs_df.loc[lambda df: df.label == label]\n",
    "    \n",
    "    pixels_are_cols = np.zeros(shape=(len(x), 1024))\n",
    "    for i in range(len(x)):\n",
    "        cur_pic = x['oneDGray'].values[i]\n",
    "        for j in range(1024):\n",
    "            pixels_are_cols[i][j] = cur_pic[j]\n",
    "    \n",
    "    x = pixels_are_cols\n",
    "    y = [True]*len(x)\n",
    "    n_comps = 175\n",
    "\n",
    "    kpca = KernelPCA(n_components=n_comps, kernel='rbf', fit_inverse_transform=True, gamma=15)\n",
    "    X_kpca = kpca.fit(x)\n",
    "    kpcas.append((x, kpca, X_kpca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, numlabels)\n",
    "for label in range(numlabels):\n",
    "    axis = axes[label] if numlabels > 1 else axes\n",
    "    #np.random.shuffle(kpcas[label][0])\n",
    "    axis.axis('off')\n",
    "    axis.imshow(recd.reshape((32,32)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DAISY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_daisy(row):\n",
    "    row = row[2]\n",
    "    feat = daisy(row.reshape((32,32)),step=10, radius=10, rings=2, histograms=6, orientations=8, visualize=False)\n",
    "    return feat.reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate bag of features for each image\n",
    "daisies = np.apply_along_axis(apply_daisy, 1, imgs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pick a random image and calculate its distance from the other images according to the DAISY features\n",
    "index1 = randint(0, len(daisies))\n",
    "# can only calculate one image's distances at a time because memory things\n",
    "dist_matrix = pairwise_distances(daisies, daisies[index1].reshape((1, -1))) \n",
    "dist_matrix[index1] = np.infty\n",
    "index2 = np.argmin(dist_matrix)\n",
    "\n",
    "# display random image and its closest match using the DAISY features\n",
    "f, axes = plt.subplots(1,2)\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "tmp = axes[0].imshow(imgs_df['oneDGray'][index1].reshape((32,32)), cmap=plt.cm.gray)\n",
    "tmp = axes[1].imshow(imgs_df['oneDGray'][index2].reshape((32,32)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between instances within classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_distances = []\n",
    "for i in range(numlabels):\n",
    "    cur_imgs = imgs_df.loc[lambda df: df.label == i]\n",
    "    cur_daisies = np.apply_along_axis(apply_daisy, 1, cur_imgs) # TODO: don't need to recalculate these DAISYs\n",
    "    dist_matrix = pairwise_distances(cur_daisies)\n",
    "    mean_distances.append(p.DataFrame(dist_matrix).mean().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.boxplot(data=mean_distances)\n",
    "tmp = ax.figure.get_axes()[0].set_xticklabels(labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
